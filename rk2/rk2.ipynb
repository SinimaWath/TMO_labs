{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рубежный контроль №2\n",
    "Тарасов Владислав, ИУ5-64, Вариант №12, Задача №1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "Необходимо решить задачу классификации текстов на основе любого выбранного Вами датасета (кроме примера, который рассматривался в лекции). Классификация может быть бинарной или многоклассовой. Целевой признак из выбранного Вами датасета может иметь любой физический смысл, примером является задача анализа тональности текста.\n",
    "\n",
    "Необходимо сформировать признаки на основе CountVectorizer или TfidfVectorizer.\n",
    "\n",
    "В качестве классификаторов необходимо использовать два классификатора, не относящихся к наивным Байесовским методам (например, LogisticRegression, LinearSVC), а также Multinomial Naive Bayes (MNB), Complement Naive Bayes (CNB), Bernoulli Naive Bayes.\n",
    "\n",
    "Для каждого метода необходимо оценить качество классификации с помощью хотя бы одной метрики качества классификации (например, Accuracy).\n",
    "\n",
    "Сделате выводы о том, какой классификатор осуществляет более качественную классификацию на Вашем наборе данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключим необходимые библиотеки и загрузим набор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Устанавливаем тип графиков\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Для лучшего качествоа графиков\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats(\"retina\")\n",
    "\n",
    "# Устанавливаем ширину экрана для отчета\n",
    "pd.set_option(\"display.width\", 70)\n",
    "\n",
    "# Загружаем данные\n",
    "data = pd.read_csv('apple-twitter-sentiment-texts.csv')\n",
    "\n",
    "# Сплитим\n",
    "train, test = np.split(data.sample(frac=1), [int(.8*len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0, -1, ..., -1,  0,  0])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(list(train['text']) + list(test['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.transform(list(train['text']))\n",
    "X_test = vectorizer.transform(list(test['text']))\n",
    "\n",
    "y_train = np.array(train['sentiment'])\n",
    "y_test = np.array(test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1304x5168 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 18458 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<326x5168 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4764 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    print(model)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"accuracy:\", accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "accuracy: 0.8404907975460123\n"
     ]
    }
   ],
   "source": [
    "test(LogisticRegression(solver='lbfgs', multi_class='auto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0)\n",
      "accuracy: 0.8680981595092024\n"
     ]
    }
   ],
   "source": [
    "test(LinearSVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "accuracy: 0.8098159509202454\n"
     ]
    }
   ],
   "source": [
    "test(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComplementNB(alpha=1.0, class_prior=None, fit_prior=True, norm=False)\n",
      "accuracy: 0.8006134969325154\n"
     ]
    }
   ],
   "source": [
    "test(ComplementNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "accuracy: 0.8098159509202454\n"
     ]
    }
   ],
   "source": [
    "test(BernoulliNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод Complement Naive Bayes, ожидаемо, лучше всего решает поставленную задачу многоклассовой классификации в условиях дисбаланса классов, но LinearSVC также показал отличный результат и практический не уступил методу Complement Naive Bayes."
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Зубков Андрей Дмитриевич"
   }
  ],
  "group": "ИУ5-64Б",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "title": "Рубежный контроль №2"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
